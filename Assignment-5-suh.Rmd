---
title: "Assignment 5 Suh"
author: "Gage Clawson"
date: "11/26/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
# Load packages
library(tidyverse)
library(RColorBrewer)
library(stargazer)
library(knitr)
library(car)
library(effsize)
library(forcats)
```


**1. Male and female graduate enrollment (1967 - 2015). Compare trends in total graduate enrollment for males and females (including full-time/part-time and private/public universities) in the United States from 1967 - 2015. Describe your results statistically, graphically and in text. **


What if we want to describe the way that one variable changes with respect to another variable?
Then we might use regression to:

* Understand how well input (x) variable(s) predict the value of an outcome (y) variable

* How do input variables influence the output value?

* Find a regression equation that *MAY* be used to make predictions for currently unknown values


4 assumptions for linear regression 

- Linearity

- Independence

- Homoscedasticity (residuals variance)

- Normality

Linear Regression Steps:

- Look at and think about your data: Does a linear relationship make the most sense, conceptually & visually?

- Run the regression: lm(y ~ x, data = df)

- Check the diagnostic plots: plot(model_name) – for evidence of homoscedasticity and normal residuals

- Communicate the results in text/table/figure  


```{r}
# Read in dataset
enroll_totals <- read_csv("Grad enrollment 1967 - 2015.csv")

#### Test for linearity ####
plot(enroll_totals$year, enroll_totals$total_males)
# male enrollment increases at a linear trend by year. 


plot(enroll_totals$year, enroll_totals$total_females)
# female enrollment increases at a linear trend by year

#### Run regressions ####

# linear regression for males predicted by year

males_lm <- lm(total_males ~ year, data = enroll_totals)
summary(males_lm)
# total_male_enrollment = -17112153 + 9069*year

# check diagnostic plots
par(mfrow = c(2,2))
plot(males_lm)
# residuals are normally distributed


# linear regression for females predicted by year

females_lm <- lm(total_females ~ year, data = enroll_totals)
summary(females_lm)
females_lm
#total_female_enrollment = -5.896e+07 + 3.013e+04*year

# at year 0 for both models, we have negative enrollment, which is impossible. This means that we likely will not have a good model for past models. 

# check diagnostic plots
par(mfrow = c(2,2))
plot(females_lm)
# residuals are normally distributed

# correlation testing for males vs year
cor.test(enroll_totals$year, enroll_totals$total_males)
# strong positive correlation

# correlation testing for females vs year 
cor.test(enroll_totals$year, enroll_totals$total_females)
#even stronger positive correlation

# Need to interpret.

```


```{r stargazer1, results = 'asis'}
m_f_enroll_lmtbl <- stargazer(males_lm, females_lm, type = "html") # not working

```


```{r}
# FINAL GRAPH: Make a time series graph with year on x axis and totals on y axis

totals_line <- ggplot(enroll_totals, aes(x = year)) +
  geom_line(aes(y = total_males, color = "blue")) +
  geom_line(aes(y = total_females, color = "red")) + 
  theme_classic() +                                                      
  scale_x_continuous(expand = c(0,0), breaks = seq(1967, 2015, by = 5), limits = c(1967, 2015)) + 
  scale_y_continuous(breaks = seq(0, 2200000, by = 200000)) +
  scale_color_manual(values = c("#00AFBB", "#E7B800"), labels = c("Males", "Females")) +
  labs(x = "Year", y = "Enrollment Totals") +
  theme(text = element_text(family = "Century Schoolbook"), legend.title=element_blank())

totals_line


# FINAL GRAPH: plot the regressions with geom_smooth
regression_graphs <- ggplot(enroll_totals, aes(x = year)) +
  geom_point(aes(y = total_males, color = "blue")) + 
  geom_smooth(aes(y = total_males, color = "blue"), method = "lm", se = TRUE) +
  geom_point(aes(y = total_females, color = "red")) +
  geom_smooth(aes(y = total_females, color = "red"), method = "lm", se = TRUE) +
  theme_classic() +
  labs(x = "Year", y = "Enrollment Totals") +
  scale_x_continuous(expand = c(0,0), breaks = seq(1967, 2015, by = 5), limits = c(1967, 2015)) +
  scale_y_continuous(breaks = seq(0, 2200000, by = 200000)) +
  scale_color_manual(values = c("skyblue1", "salmon"), labels = c("Males", "Females")) +
  theme(text = element_text(family = "Century Schoolbook"), legend.title=element_blank(), legend.box.background = element_rect(colour = "grey"), panel.background = element_rect(fill = "white")) +
  annotate("text", x = 1997, y = 1600000, label = "Y = -58,955,502 + 30,126X", family = "Century Schoolbook") +
   annotate("text", x = 1997, y = 1500000, label = expression(R^2~0.98) , family = "Century Schoolbook") 
  
  
regression_graphs

```

female: y = ...

male: y = ...

**2. Shifts in female PhD recipients by field (1985, 2000, and 2015). Describe if and how there was a shift in PhDs awarded to females in four fields (Physical and Earth Sciences, Engineering, Education, and Humanities & Arts) in 1985, 2000, and 2015. Describe your results statistically, in a graph or table, and in text. Note: There are several ways that you can interpret this question. You are invited to decide which you think is/are most interesting. Just be really clear about what you are asking/answering in your report.**

```{r}
female_phd <- read_csv("PhDs by Field 1985 - 2015.csv")

female_phd1 <- select(female_phd, -year)  # delete year column

rownames(female_phd1) <- c("1985", "2000", "2015")   # name rows as year

female_phd_prop <- prop.table(as.matrix(female_phd1), 1)  #create proportion table

female_phd_x2 <- chisq.test(female_phd1)   #perform chisquare test

female_phd_x2  ####### ilayda add total enrollment column #######

# females moved out of education, and into the sciences and engineering (engineering especially). The humanities generally stayed the same. 

# Ilayda make table adding in the total enrollment of females column 
```

```{r}
#adding stacked barchart to see if we want to use it
stacked_bar_data <- read_csv("female_phd_stackedbar.csv")

stacked_bar_data$year <- as.character(stacked_bar_data$year)

stacked_bar <- ggplot(stacked_bar_data, aes(x = year, y = degrees_awarded, fill = field_of_study)) +
  geom_bar(stat = "identity") +
  theme_classic() +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  theme(text = element_text(family = "Century Schoolbook"), legend.box.background = element_rect(colour = "grey")) +
  scale_fill_discrete(name = "Field of Study") +
  labs(x = "Year", y = "Degrees Awarded")  + 
  annotate("text", x = 1, y = 270, label = "10.1%", family = "Century Schoolbook") +
  annotate("text", x = 1, y = 1300, label = "24.6%", family = "Century Schoolbook") +
  annotate("text", x = 1, y = 2075, label = "3.5%", family = "Century Schoolbook") +
  annotate("text", x = 1, y = 3700, label = "61.8%", family = "Century Schoolbook") +
  annotate("text", x = 2, y = 500, label = "11.7%", family = "Century Schoolbook") +
  annotate("text", x = 2, y = 2400, label = "30.7%", family = "Century Schoolbook") +
  annotate("text", x = 2, y = 4100, label = "9.6%", family = "Century Schoolbook") +
  annotate("text", x = 2, y = 6500, label = "48.0%", family = "Century Schoolbook") +
  annotate("text", x = 3, y = 900, label = "18.7%", family = "Century Schoolbook") +
  annotate("text", x = 3, y = 3300, label = "26.7%", family = "Century Schoolbook") +
  annotate("text", x = 3, y = 6000, label = "21.7%", family = "Century Schoolbook") +
  annotate("text", x = 3, y = 8800, label = "32.9%", family = "Century Schoolbook") 
  
  
stacked_bar
```




**3. Male and female salaries for starting postdoctoral and other employment positions (2015). Compare median salaries for male and female doctorate recipients in 2015. Answer these two questions: Does median salary differ significantly between male and female starting postdoc positions? Does median salary differ significantly between male and female PhD recipients in non-postdoc employment positions?**


- First test for equal variance

- wilcoxon signed rank (paired) ??

- Cliffs Delta (effect size)

- Actual difference in medians -- does this apply here? I don't think taking the median of medians makes sense??

```{r}
med_sal <- read_csv("Median salary for doctoral recipients cleaned.csv")


######################## Post Doctoral Work ############################
# Test for equal variance
# H0: Variances are equal
# HA: Variances are not equal

var_test_p <- var.test(med_sal$p_sal_m, med_sal$p_sal_f)
var_test_p
 # retain the null hypothesis that the variances are equal

# Exploratory graphs
# hist for male median salary postdoctoral


p_male_hist <- ggplot(aes(x = p_sal_m), data = med_sal) +
  geom_histogram(bins = 4.932424)
p_male_hist
# seems relatively normal

p_female_hist <- ggplot(aes(x = p_sal_f), data = med_sal) +
  geom_histogram(bins = 4.932424)
p_female_hist
# seems relatively normal


# H0: There is not a significant difference in ranks for male and female post doc positions
# HA: There is a significant difference in ranks for male and female post doc positions
wsr_salaries_p <- wilcox.test(med_sal$p_sal_m, med_sal$p_sal_f, paired = TRUE) 

wsr_salaries_p
# p = 0.8671
# this tells us to retain null. There is no significant diff between male and female post doc positions among field.

# Cliffs delta
p_sal_delta <- cliff.delta(med_sal$p_sal_m, med_sal$p_sal_f)
p_sal_delta
# effect size is 0.04 (negligible)

# Actual difference in medians
# median(med_sal$p_sal_m) - median(med_sal$p_sal_f)
# difference = 3000

med_sal_p <- med_sal %>%
  select(field_of_study, p_sal_m, p_sal_f) %>%
  mutate(difference = p_sal_m - p_sal_f)

########################## non postdoctoral work #########################################
# Test for equal variance
# H0: Variances are equal
# HA: Variances are not equal

var_test_np <- var.test(med_sal$np_sal_m, med_sal$np_sal_f)
var_test_np
 # retain the null hypothesis that the variances are equal

# Exploratory graphs
# hist for male median salary postdoctoral


np_male_hist <- ggplot(aes(x = np_sal_m), data = med_sal) +
  geom_histogram(bins = 4.932424)
np_male_hist
# seems relatively normal

np_female_hist <- ggplot(aes(x = np_sal_f), data = med_sal) +
  geom_histogram(bins = 4.932424)
np_female_hist
# seems relatively normal


# H0: There is not a significant difference in ranks for male and female non post doc positions
# HA: There is a significant difference in ranks for male and female non post doc positions
wsr_salaries_np <- wilcox.test(med_sal$np_sal_m, med_sal$np_sal_f, paired = TRUE) 

wsr_salaries_np
# p = 0.002572
# this tells us to reject null. There is significant diff between male and female non post doc positions among field of study. 

# Cliffs delta
np_sal_delta <- cliff.delta(med_sal$np_sal_m, med_sal$np_sal_f)
np_sal_delta
# effect size is 0.213333 (SMALL)

# Actual difference in medians
# median(med_sal$np_sal_m) - median(med_sal$np_sal_f)
# difference = 3417

med_sal_np <- med_sal %>%
  select(field_of_study, np_sal_m, np_sal_f) %>%
  mutate(difference = np_sal_m - np_sal_f)
```

Institutions have set pay grades which is why there is less of a difference among the medians for postdoc work. 


**4. Exploring academic salaries for professors in U.S. colleges. Explore relationships between variables in the ‘Faculty salary data (2008 - 2009 survey)’ dataset. Develop a model describing faculty salary based on data for faculty sex, rank, years in current position, field, and number of years since doctoral degree was earned. You should make decisions regarding which variables should remain in your final model. Describe the results qualitatively and quantitatively (i.e., don’t just report the statistical results of the model – make sure you describe interesting findings in text). You can also discuss any concerns that you have with the model(s) you present, if any.**


H0: The model does not significantly predict the outcome (i.e., there is no relationship between the model and the outcome; no variables significantly
predict outcome)
HA: AT LEAST ONE of the explanatory variables significantly predicts the outcome 


How do I know which model is the BEST one?

- STATISTICS IS NO SUBSTITUTE FOR JUDGMENT.

- ASSUMPTIONS.

- AKAIKE INFORMATION CRITERION.

Signs	and	Symptoms	of	Collinearity

- High	correlation	between	predictor	variables

- Large	standard	errors	for	regression coefficient

- Large	changes	in	model	output	for	small changes	in	predictor	variable	inputs

- Illogical/unexpected	 coefficients	 (esp. coefficient	sign)

Variance	Inflation	Factor

- How	much	the	variance	in	coefficients	is	inflated (compared	 to	the	variance	if	there	were	no correlation	 between	model	variables)	

- VIF	=	1:	No	correlation	(variance	is	not	inflated	at	all	by	correlation with	other	predictor	variables)

- VIF	>	4:	Eeehhh…some	correlation,	investigate	further	and	think critically about possible overlaps in explanatory	variables

- VIF	>	10:	Serious	correlation	between	variables	that	may	be strongly	inflating	coefficient	variance	and	error



```{r}
faculty_salary <- read_csv("Faculty salary data (2008 - 2009 survey).csv")

# look at relationships between variables

plot(faculty_salary$years_since, faculty_salary$salary) # looks ok
plot(faculty_salary$years_service, faculty_salary$salary) # looks ok
plot(faculty_salary$years_since, faculty_salary$years_service) # definitely colinear



# a. Set rank to class 'factor'
faculty_salary$rank <- as.factor(faculty_salary$rank)

# d. Reassign reference level of "rank" to "AsstProf":
faculty_salary$rank <- fct_relevel(faculty_salary$rank, "AsstProf")
levels(faculty_salary$rank)


# a. Set field to class 'factor'
faculty_salary$field <- as.factor(faculty_salary$field)

# d. Reassign reference level of "Status" to "Regular":
faculty_salary$field <- fct_relevel(faculty_salary$field, "Theoretical")
levels(faculty_salary$field)


# saturated model
test_lm1 <- lm(salary ~ rank + field + years_since + years_service + sex, data = faculty_salary)
summary(test_lm1)
plot(test_lm1)
# heteroskedastic

vif(test_lm1)
# years since = 7.5
# years service = 5.9
# just as we expected, most likely colinear. Should be concerned. Lets try taking out years since phd. 


test_lm2 <- lm(salary ~ rank + field + years_service + sex, data = faculty_salary)
summary(test_lm2)
plot(test_lm2)
#heteroskedastic


vif(test_lm2)
# everything is ok here



test_lm3 <- lm(salary ~ rank + field + years_since + sex, data = faculty_salary)
summary(test_lm3)
plot(test_lm3)

### check AIC to determine which is better. Still we should trust our judgement here though

AIC(test_lm1)
#9093.826

AIC(test_lm2)
#9096.813

AIC(test_lm3)
#9097.22


ggplot(aes(x = years_service, y = salary, color = field), data = faculty_salary) +
  geom_point() + 
  geom_smooth(aes(years_service, salary, color = field), method = lm, se = FALSE)

ggplot(aes(x = years_since, y = salary, color = field), data = faculty_salary) +
  geom_point() + 
  geom_smooth(aes(years_since, salary, color = field), method = lm, se = FALSE) +
  theme_classic() +
  labs(x = "Years Since PHD", y = "Salary", color = "Field") +
  theme(text = element_text(family = "Century Schoolbook"))
  

ggplot(aes(x = years_service, y = salary, color = rank), data = faculty_salary) +
  geom_point() + 
  geom_smooth(aes(years_service, salary, color = rank), method = lm, se = FALSE)

ggplot(aes(x = years_since, y = salary, color = rank), data = faculty_salary) +
  geom_point() + 
  geom_smooth(aes(years_since, salary, color = rank), method = lm, se = FALSE)

##interaction term for field and years_since

test_lm4 <- lm(salary ~ rank + field + years_since + sex + years_since*field, data = faculty_salary)
summary(test_lm4)
##### use this model^^^^^ - it makes the most sense in the context of the numbers. Applied should make more than theoretical. Prof and Assoc prof should make more than assistant prof. Salary should increase per each year since phd. Males likely make more money than females. Applied per year should be more than theoretical per year. The rest of the models below do not meet all of these assumptions. 

vif(test_lm4)

AIC(test_lm4)
#9098.798

##interaction term for rank and years_since
test_lm5 <- lm(salary~ rank + field + years_since + sex + years_since*rank, data = faculty_salary)
summary(test_lm5)

##interaction term for rank and years_service
test_lm6 <- lm(salary~ rank + field + years_service + sex + years_service*rank, data = faculty_salary)
summary(test_lm6)

##interaction term for field and years_service
test_lm7 <- lm(salary~ rank + field + years_service + sex + years_service*field, data = faculty_salary)
summary(test_lm7)



```

```{r stargazer, results = 'asis'}
stargazer(test_lm3, test_lm4, type = "html")
```


```{r}

######################## THIS IS NOT RIGHT ################################

#predict values and graph

df_new <- data.frame(rank = rep(c("Prof",
                                  "AsstProf",
                                  "AssocProf"),
                                times = 12,
                                each = 20), 
                     field = rep(c("Applied",
                                    "Theoretical"),
                                  each = 360), 
                     years_since = rep(seq(from = 1, 
                                           to = 60, 
                                           length = 20),
                                       times = 12), 
                     sex = rep(c("Male", 
                                 "Female"), 
                               each = 360),
                     salary = rep(seq(from = 55000,
                                    to = 235000, 
                                    length = 20), 
                                times = 12)) 

# a. Make predictions using the new data frame:
salary_predict <- as.data.frame(predict(test_lm4, newdata = df_new, se.fit = TRUE, interval = "confidence"))

# b. Bind predictions to the data to make it actually useful:
predict_df <- data.frame(df_new, salary_predict)

```


```{r}
#line graph of predictions 
predict_graph <- ggplot(predict_df, aes(x = years_since, y = fit.fit)) +
  geom_line(aes(color = rank)) +
  facet_wrap(~field)
predict_graph

```




